{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17784026-86a6-4a35-84cc-742db1966e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:47:37.468097Z",
     "iopub.status.busy": "2024-12-15T08:47:37.467909Z",
     "iopub.status.idle": "2024-12-15T08:47:38.621971Z",
     "shell.execute_reply": "2024-12-15T08:47:38.621061Z",
     "shell.execute_reply.started": "2024-12-15T08:47:37.468082Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb90fcf4-e7b8-4199-828e-a5eb39fe2847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:23.704329Z",
     "iopub.status.busy": "2024-12-15T08:57:23.703670Z",
     "iopub.status.idle": "2024-12-15T08:57:23.712917Z",
     "shell.execute_reply": "2024-12-15T08:57:23.710770Z",
     "shell.execute_reply.started": "2024-12-15T08:57:23.704283Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = 'meta-llama/Llama-2-7b'\n",
    "model_name = 'meta-llama/Llama-3.1-8B'\n",
    "# model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "# model_name = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32c719ff-2b41-4bd2-b8db-e5605ca4329a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:25.031335Z",
     "iopub.status.busy": "2024-12-15T08:57:25.030736Z",
     "iopub.status.idle": "2024-12-15T08:57:25.920480Z",
     "shell.execute_reply": "2024-12-15T08:57:25.918596Z",
     "shell.execute_reply.started": "2024-12-15T08:57:25.031289Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d017c31-0dc1-42e2-bf44-eaff44922e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:27.295351Z",
     "iopub.status.busy": "2024-12-15T08:57:27.295059Z",
     "iopub.status.idle": "2024-12-15T08:57:27.305237Z",
     "shell.execute_reply": "2024-12-15T08:57:27.303165Z",
     "shell.execute_reply.started": "2024-12-15T08:57:27.295332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d79b1a2-c8ae-427c-ad1d-833132bb73de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:28.560478Z",
     "iopub.status.busy": "2024-12-15T08:57:28.559679Z",
     "iopub.status.idle": "2024-12-15T08:57:28.571782Z",
     "shell.execute_reply": "2024-12-15T08:57:28.569652Z",
     "shell.execute_reply.started": "2024-12-15T08:57:28.560410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ff383-70b7-4d41-89cd-03e3322c5956",
   "metadata": {},
   "source": [
    "### `tokenizer.pad_token = tokenizer.eos_token`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df75f8-7542-4f85-acaa-70f83cc62467",
   "metadata": {},
   "source": [
    "- training\n",
    "    - sent1: \"Hello, how are you?\"\n",
    "        - `[\"Hello,\", \" how\", \" are\", \" you?\", <eos>]`\n",
    "    - sent2: \"I am fine.\"\n",
    "        - `[\"I\", \" am\", \"fine.\", <eos>]`\n",
    "- padding for batch processing\n",
    "    - sent1: `[\"Hello,\", \" how\", \" are\", \" you?\", <eos>]`\n",
    "    - sent2: `[\"I\", \" am\", \"fine.\", <eos>, <pad>]`\n",
    "- pad_token = eos_token\n",
    "    - sent1: `[\"Hello,\", \" how\", \" are\", \" you?\", <eos>]`\n",
    "    - sent2: `[\"I\", \" am\", \"fine.\", <eos>, <eos>]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "495951f1-9f2f-45ba-91bb-079099f3da6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:30.338552Z",
     "iopub.status.busy": "2024-12-15T08:57:30.337929Z",
     "iopub.status.idle": "2024-12-15T08:57:30.346729Z",
     "shell.execute_reply": "2024-12-15T08:57:30.344545Z",
     "shell.execute_reply.started": "2024-12-15T08:57:30.338492Z"
    }
   },
   "outputs": [],
   "source": [
    "sent1 = \"Hello, how are you?\"\n",
    "sent2 = \"I am fine.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0bb9cee-74cc-4acf-a64e-920086dbd942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:33.734907Z",
     "iopub.status.busy": "2024-12-15T08:57:33.734272Z",
     "iopub.status.idle": "2024-12-15T08:57:33.747140Z",
     "shell.execute_reply": "2024-12-15T08:57:33.744992Z",
     "shell.execute_reply.started": "2024-12-15T08:57:33.734862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 9906, 11, 1268, 527, 499, 30]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "981fa5ac-f189-4711-9183-1602517278f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:58:19.807660Z",
     "iopub.status.busy": "2024-12-15T08:58:19.807032Z",
     "iopub.status.idle": "2024-12-15T08:58:19.820964Z",
     "shell.execute_reply": "2024-12-15T08:58:19.818685Z",
     "shell.execute_reply.started": "2024-12-15T08:58:19.807611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'Ġhow', 'Ġare', 'Ġyou', '?']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76697c56-207c-4df1-9f71-5acaaaac0736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:57:38.658957Z",
     "iopub.status.busy": "2024-12-15T08:57:38.658305Z",
     "iopub.status.idle": "2024-12-15T08:57:38.672029Z",
     "shell.execute_reply": "2024-12-15T08:57:38.669897Z",
     "shell.execute_reply.started": "2024-12-15T08:57:38.658910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|begin_of_text|>', '?')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(128000), tokenizer.decode(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42f654-7727-4532-8ba1-74264fd44926",
   "metadata": {},
   "source": [
    "### gpt2 generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af1efd-60c0-4537-927c-051b3bb39001",
   "metadata": {},
   "source": [
    "- **The issue being GPT2 model adds position embeddings to every token in the input sequence including pad_tokens.**\n",
    "    - https://github.com/huggingface/transformers/issues/21080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627c3515-e986-4b34-8d30-cda689dffc71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:51:12.150418Z",
     "iopub.status.busy": "2024-12-16T13:51:12.149786Z",
     "iopub.status.idle": "2024-12-16T13:51:19.052451Z",
     "shell.execute_reply": "2024-12-16T13:51:19.051218Z",
     "shell.execute_reply.started": "2024-12-16T13:51:12.150370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# run this only for gpt-2 as we do not have a pad token in gpt2\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', pad_token_id = tokenizer.eos_token_id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953c78db-9f84-4b92-9cf5-a5783ec961c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:57:34.005782Z",
     "iopub.status.busy": "2024-12-16T13:57:34.005475Z",
     "iopub.status.idle": "2024-12-16T13:57:34.016010Z",
     "shell.execute_reply": "2024-12-16T13:57:34.013844Z",
     "shell.execute_reply.started": "2024-12-16T13:57:34.005760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|endoftext|>', 50256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3caeb06-77b0-4e6e-b7e4-a36778eb693f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:51:19.053607Z",
     "iopub.status.busy": "2024-12-16T13:51:19.053311Z",
     "iopub.status.idle": "2024-12-16T13:51:19.062811Z",
     "shell.execute_reply": "2024-12-16T13:51:19.062282Z",
     "shell.execute_reply.started": "2024-12-16T13:51:19.053590Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"I went to the\"\n",
    "\n",
    "results = tokenizer(\n",
    "\t[sentence],\n",
    "\tadd_special_tokens=True,\n",
    "\ttruncation=True,\n",
    "\tpadding=True,\n",
    "\treturn_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37725f6f-62ad-411e-b6d6-9680ed52fc3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:51:22.562400Z",
     "iopub.status.busy": "2024-12-16T13:51:22.562132Z",
     "iopub.status.idle": "2024-12-16T13:51:22.581262Z",
     "shell.execute_reply": "2024-12-16T13:51:22.578803Z",
     "shell.execute_reply.started": "2024-12-16T13:51:22.562382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  40, 1816,  284,  262]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964583e9-656f-4bf7-875d-d7bbd47afaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:51:35.860285Z",
     "iopub.status.busy": "2024-12-16T13:51:35.859627Z",
     "iopub.status.idle": "2024-12-16T13:51:35.871210Z",
     "shell.execute_reply": "2024-12-16T13:51:35.869318Z",
     "shell.execute_reply.started": "2024-12-16T13:51:35.860237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= With No Padding ==========\n",
      "Tokenizing the input sentence \"I went to the\" leads to \n",
      "['I', 'Ġwent', 'Ġto', 'Ġthe']\n"
     ]
    }
   ],
   "source": [
    "print(\"========= With No Padding ==========\")\n",
    "\n",
    "print(\"Tokenizing the input sentence \\\"{0}\\\" leads to \".format(sentence) )\n",
    "print(tokenizer.convert_ids_to_tokens( results['input_ids'][0] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f20ebf-823a-4144-b73d-bcc277276817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:51:49.158401Z",
     "iopub.status.busy": "2024-12-16T13:51:49.157751Z",
     "iopub.status.idle": "2024-12-16T13:51:49.872917Z",
     "shell.execute_reply": "2024-12-16T13:51:49.871094Z",
     "shell.execute_reply.started": "2024-12-16T13:51:49.158354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the Ġhospital\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\tlogits = model(results['input_ids'].to(device), \n",
    "\t\t\t\t\tattention_mask=results['attention_mask'].to(device),\n",
    "\t\t\t\t\t).logits[:, -1, :]\n",
    "\tindex = torch.argmax(logits).item()\n",
    "\tprint( sentence + \" \" +  tokenizer.convert_ids_to_tokens(index) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53e4020-c508-4cf6-814a-94fbcd099457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:52:10.539585Z",
     "iopub.status.busy": "2024-12-16T13:52:10.539275Z",
     "iopub.status.idle": "2024-12-16T13:52:10.547632Z",
     "shell.execute_reply": "2024-12-16T13:52:10.545932Z",
     "shell.execute_reply.started": "2024-12-16T13:52:10.539565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Using Padding of size 30 ==========\n"
     ]
    }
   ],
   "source": [
    "max_length= 30\n",
    "print(\"========= Using Padding of size {0} ==========\".format(max_length))\n",
    "\n",
    "results = tokenizer(\n",
    "    [sentence],\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=False,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba6b9cb-7df1-4de2-bf1b-2688344b0660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:52:15.817038Z",
     "iopub.status.busy": "2024-12-16T13:52:15.816226Z",
     "iopub.status.idle": "2024-12-16T13:52:15.829264Z",
     "shell.execute_reply": "2024-12-16T13:52:15.827032Z",
     "shell.execute_reply.started": "2024-12-16T13:52:15.816980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the padded input sentence \"I went to the\" leads to \n",
      "['<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', 'I', 'Ġwent', 'Ġto', 'Ġthe']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing the padded input sentence \\\"{0}\\\" leads to \".format(sentence) )\n",
    "print(tokenizer.convert_ids_to_tokens( results['input_ids'][0] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ce10c8-0880-4807-836c-a3a4627a479a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:52:23.129280Z",
     "iopub.status.busy": "2024-12-16T13:52:23.128641Z",
     "iopub.status.idle": "2024-12-16T13:52:23.207464Z",
     "shell.execute_reply": "2024-12-16T13:52:23.205639Z",
     "shell.execute_reply.started": "2024-12-16T13:52:23.129235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the Ġthe\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(results['input_ids'].to(device), \n",
    "                    attention_mask=results['attention_mask'].to(device),\n",
    "                    ).logits[:, -1, :]\n",
    "    index = torch.argmax(logits).item()\n",
    "    print( sentence + \" \" +  tokenizer.convert_ids_to_tokens(index) )\n",
    "\n",
    "print(\"\\n\" * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf2ead1-bc72-4183-911c-6d8f102bdac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:53:03.312633Z",
     "iopub.status.busy": "2024-12-16T13:53:03.312262Z",
     "iopub.status.idle": "2024-12-16T13:53:03.333984Z",
     "shell.execute_reply": "2024-12-16T13:53:03.331629Z",
     "shell.execute_reply.started": "2024-12-16T13:53:03.312609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= With No Padding ==========\n",
      "Tokenizing the input sentence \"I went to the\" leads to \n",
      "['I', 'Ġwent', 'Ġto', 'Ġthe']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the\"\n",
    "\n",
    "results = tokenizer(\n",
    "\t[sentence],\n",
    "\tadd_special_tokens=True,\n",
    "\ttruncation=True,\n",
    "\tpadding=True,\n",
    "\treturn_tensors='pt',\n",
    ")\n",
    "\n",
    "position_ids = torch.zeros(results['attention_mask'].size(), dtype=torch.int32)\n",
    "starting_index = 0\n",
    "for index in range(results['attention_mask'][0].size(0)):\n",
    "    if results['attention_mask'][0][index] == 1:\n",
    "        position_ids[0][index] = starting_index\n",
    "        starting_index += 1\n",
    "\n",
    "print(\"========= With No Padding ==========\")\n",
    "\n",
    "print(\"Tokenizing the input sentence \\\"{0}\\\" leads to \".format(sentence) )\n",
    "print(tokenizer.convert_ids_to_tokens( results['input_ids'][0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adebe618-1818-4947-a01c-b1dda89cebff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:53:12.310244Z",
     "iopub.status.busy": "2024-12-16T13:53:12.309578Z",
     "iopub.status.idle": "2024-12-16T13:53:12.353007Z",
     "shell.execute_reply": "2024-12-16T13:53:12.350729Z",
     "shell.execute_reply.started": "2024-12-16T13:53:12.310197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the Ġhospital\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\tlogits = model(results['input_ids'].to(device), \n",
    "\t\t\t\t\tattention_mask=results['attention_mask'].to(device),\n",
    "                    position_ids=position_ids.to(device),\n",
    "\t\t\t\t\t).logits[:, -1, :]\n",
    "\tindex = torch.argmax(logits).item()\n",
    "\tprint( sentence + \" \" +  tokenizer.convert_ids_to_tokens(index) )\n",
    "\n",
    "print(\"\\n\" * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4a852b1-4644-475e-90db-68cfa35c876e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:58:47.348709Z",
     "iopub.status.busy": "2024-12-16T13:58:47.348044Z",
     "iopub.status.idle": "2024-12-16T13:58:47.363376Z",
     "shell.execute_reply": "2024-12-16T13:58:47.361208Z",
     "shell.execute_reply.started": "2024-12-16T13:58:47.348650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Using Padding of size 30 ==========\n",
      "Tokenizing the padded input sentence \"I went to the\" leads to \n",
      "['<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', 'I', 'Ġwent', 'Ġto', 'Ġthe']\n"
     ]
    }
   ],
   "source": [
    "max_length= 30\n",
    "print(\"========= Using Padding of size {0} ==========\".format(max_length))\n",
    "\n",
    "results = tokenizer(\n",
    "    [sentence],\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=False,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',\n",
    ")\n",
    "\n",
    "print(\"Tokenizing the padded input sentence \\\"{0}\\\" leads to \".format(sentence) )\n",
    "print(tokenizer.convert_ids_to_tokens( results['input_ids'][0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25039771-2f0a-47cf-89c7-303109b84c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:58:53.859025Z",
     "iopub.status.busy": "2024-12-16T13:58:53.858388Z",
     "iopub.status.idle": "2024-12-16T13:58:53.871749Z",
     "shell.execute_reply": "2024-12-16T13:58:53.869585Z",
     "shell.execute_reply.started": "2024-12-16T13:58:53.858979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256,    40,  1816,   284,   262])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a014963-71db-4113-87cf-45514a69f03b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:53:24.982493Z",
     "iopub.status.busy": "2024-12-16T13:53:24.981912Z",
     "iopub.status.idle": "2024-12-16T13:53:25.023142Z",
     "shell.execute_reply": "2024-12-16T13:53:25.021015Z",
     "shell.execute_reply.started": "2024-12-16T13:53:24.982450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the Ġhospital\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "position_ids = torch.zeros(results['attention_mask'].size(), dtype=torch.int32)\n",
    "starting_index = 0\n",
    "for index in range(results['attention_mask'][0].size(0)):\n",
    "    if results['attention_mask'][0][index] == 1:\n",
    "        position_ids[0][index] = starting_index\n",
    "        starting_index += 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(results['input_ids'].to(device), \n",
    "                    attention_mask=results['attention_mask'].to(device),\n",
    "                    position_ids=position_ids.to(device),\n",
    "                    ).logits[:, -1, :]\n",
    "    index = torch.argmax(logits).item()\n",
    "    print( sentence + \" \" +  tokenizer.convert_ids_to_tokens(index) )\n",
    "\n",
    "print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d306419-9390-4e91-85fc-b88bc3f7fe89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:55:29.446036Z",
     "iopub.status.busy": "2024-12-16T13:55:29.445720Z",
     "iopub.status.idle": "2024-12-16T13:55:29.459683Z",
     "shell.execute_reply": "2024-12-16T13:55:29.457303Z",
     "shell.execute_reply.started": "2024-12-16T13:55:29.446016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 1, 1]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 2, 3]], dtype=torch.int32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['attention_mask'], position_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54824392-f15c-4b90-b317-e79e1139675f",
   "metadata": {},
   "source": [
    "### batch generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1ff0d24-ea21-4874-8a5e-75109b87450b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:59:47.717774Z",
     "iopub.status.busy": "2024-12-16T13:59:47.717335Z",
     "iopub.status.idle": "2024-12-16T13:59:48.995743Z",
     "shell.execute_reply": "2024-12-16T13:59:48.993556Z",
     "shell.execute_reply.started": "2024-12-16T13:59:47.717744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50256, 50256, 50256, 50256, 50256, 50256,    40,  1816,   284,   262],\n",
       "        [50256, 50256, 50256, 50256, 50256, 50256,   732,   389,  2111,   284],\n",
       "        [  464,  4007,   286,   428, 20243,   318,   284,  2198,  1771,   356]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', pad_token_id = tokenizer.eos_token_id)\n",
    "prompt_text = ['I went to the',\n",
    "               'we are trying to',\n",
    "               'The purpose of this workshop is to check whether we can']\n",
    "encodings_dict = tokenizer.batch_encode_plus(prompt_text, max_length=10, pad_to_max_length=True, return_tensors= \"pt\")\n",
    "encodings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59a7f1b7-3697-46e3-bef1-561d6d95c654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T13:59:54.486748Z",
     "iopub.status.busy": "2024-12-16T13:59:54.486086Z",
     "iopub.status.idle": "2024-12-16T13:59:54.685992Z",
     "shell.execute_reply": "2024-12-16T13:59:54.685207Z",
     "shell.execute_reply.started": "2024-12-16T13:59:54.486686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11311/2852500117.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encodings_dict['input_ids'])\n",
      "/tmp/ipykernel_11311/2852500117.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn_mask = torch.tensor(encodings_dict['attention_mask'])\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>I went to the hospital and was told that',\n",
       " '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>we are trying to get the best out of',\n",
       " 'The purpose of this workshop is to check whether we can make a difference in']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "attn_mask = torch.tensor(encodings_dict['attention_mask'])\n",
    "tokenizer.batch_decode(model.generate(input_ids, attention_mask=attn_mask, max_length=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9edf17-3ce0-4369-b1f5-a74de922f40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
