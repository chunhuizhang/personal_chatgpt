{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3a1dd-4631-49a9-9927-2799bac2533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9838163-65ae-4ac3-a08c-82ea82e69f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade trl\n",
    "# !pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bd26ad-c9e4-4198-8117-bc2640a84aab",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2024-07-22T14:37:17.144983Z",
     "shell.execute_reply": "2024-07-22T14:37:17.143550Z",
     "shell.execute_reply.started": "2024-07-22T14:37:05.471969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-22 22:37:16,889] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e091e0-b0b3-49e9-ba3a-e9ef1dfef0c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:17.146772Z",
     "iopub.status.busy": "2024-07-22T14:37:17.146334Z",
     "iopub.status.idle": "2024-07-22T14:37:17.155078Z",
     "shell.execute_reply": "2024-07-22T14:37:17.153823Z",
     "shell.execute_reply.started": "2024-07-22T14:37:17.146751Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a1b13-45ac-407a-a2ff-71df851f6361",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e7d77a-635d-4a06-bd96-16537289417a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:17.155891Z",
     "iopub.status.busy": "2024-07-22T14:37:17.155688Z",
     "iopub.status.idle": "2024-07-22T14:37:17.175034Z",
     "shell.execute_reply": "2024-07-22T14:37:17.173348Z",
     "shell.execute_reply.started": "2024-07-22T14:37:17.155874Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_token = \"<|pad|>\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "new_model = \"Llama-3-8B-Instruct-Finance-RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b39e2-8b4e-47fb-8f14-3f12d447e10b",
   "metadata": {},
   "source": [
    "## model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b270cc26-e26a-44d2-bd3c-2ffb15ca2b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:17.177900Z",
     "iopub.status.busy": "2024-07-22T14:37:17.177650Z",
     "iopub.status.idle": "2024-07-22T14:37:18.163873Z",
     "shell.execute_reply": "2024-07-22T14:37:18.162565Z",
     "shell.execute_reply.started": "2024-07-22T14:37:17.177882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0228da24-a453-42d2-9ff4-1fa573f9a5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:18.168411Z",
     "iopub.status.busy": "2024-07-22T14:37:18.168195Z",
     "iopub.status.idle": "2024-07-22T14:37:18.178398Z",
     "shell.execute_reply": "2024-07-22T14:37:18.177168Z",
     "shell.execute_reply.started": "2024-07-22T14:37:18.168393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map, tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b83ef88-a801-4b3f-b7e7-5168104952b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:18.179192Z",
     "iopub.status.busy": "2024-07-22T14:37:18.178991Z",
     "iopub.status.idle": "2024-07-22T14:37:18.195641Z",
     "shell.execute_reply": "2024-07-22T14:37:18.193957Z",
     "shell.execute_reply.started": "2024-07-22T14:37:18.179175Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": pad_token})\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02428daa-e2cc-41d1-9195-677b06e4451e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:18.197071Z",
     "iopub.status.busy": "2024-07-22T14:37:18.196860Z",
     "iopub.status.idle": "2024-07-22T14:37:23.921227Z",
     "shell.execute_reply": "2024-07-22T14:37:23.920427Z",
     "shell.execute_reply.started": "2024-07-22T14:37:18.197054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8264dfadeb44885bbc70ca01a958397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    #     attn_implementation=\"flash_attention_2\",\n",
    "    #     attn_implementation=\"sdpa\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc7aea2-c662-4b8f-b060-22ae454650c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:23.922081Z",
     "iopub.status.busy": "2024-07-22T14:37:23.921931Z",
     "iopub.status.idle": "2024-07-22T14:37:23.927929Z",
     "shell.execute_reply": "2024-07-22T14:37:23.926915Z",
     "shell.execute_reply.started": "2024-07-22T14:37:23.922069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.added_tokens_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa0e0ed-b4ea-4d70-ac40-7887f73c6dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:23.929847Z",
     "iopub.status.busy": "2024-07-22T14:37:23.929479Z",
     "iopub.status.idle": "2024-07-22T14:37:23.971679Z",
     "shell.execute_reply": "2024-07-22T14:37:23.970775Z",
     "shell.execute_reply.started": "2024-07-22T14:37:23.929817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(128256, 4096), 128000, 128257)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens, tokenizer.vocab_size, len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2914e036-7bee-4117-a1e6-b91dc5ac3f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:23.973014Z",
     "iopub.status.busy": "2024-07-22T14:37:23.972756Z",
     "iopub.status.idle": "2024-07-22T14:37:24.002802Z",
     "shell.execute_reply": "2024-07-22T14:37:24.001901Z",
     "shell.execute_reply.started": "2024-07-22T14:37:23.972993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128264, 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07a1a3d-3511-4403-98ac-71353be9d22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:24.003782Z",
     "iopub.status.busy": "2024-07-22T14:37:24.003526Z",
     "iopub.status.idle": "2024-07-22T14:37:24.009453Z",
     "shell.execute_reply": "2024-07-22T14:37:24.008568Z",
     "shell.execute_reply.started": "2024-07-22T14:37:24.003761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16032.125, 16033.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128257/8, 128264/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8573baa3-017a-4871-8898-7ab5e7b88334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:24.010667Z",
     "iopub.status.busy": "2024-07-22T14:37:24.010428Z",
     "iopub.status.idle": "2024-07-22T14:37:24.018102Z",
     "shell.execute_reply": "2024-07-22T14:37:24.017199Z",
     "shell.execute_reply.started": "2024-07-22T14:37:24.010647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": false,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.42.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 128264\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5028c28e-da27-4d22-901b-97d2a37a860a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:24.019326Z",
     "iopub.status.busy": "2024-07-22T14:37:24.019079Z",
     "iopub.status.idle": "2024-07-22T14:37:24.027387Z",
     "shell.execute_reply": "2024-07-22T14:37:24.026341Z",
     "shell.execute_reply.started": "2024-07-22T14:37:24.019305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> 128000\n",
      "<|end_of_text|> 128001\n",
      "<|pad|> 128256\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token, tokenizer.bos_token_id)\n",
    "print(tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb2679-ed71-490d-95cb-7d5e9555064c",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e41b83-f3cb-4c09-8d69-9e79b63a55c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:24.029333Z",
     "iopub.status.busy": "2024-07-22T14:37:24.028598Z",
     "iopub.status.idle": "2024-07-22T14:37:29.974945Z",
     "shell.execute_reply": "2024-07-22T14:37:29.973718Z",
     "shell.execute_reply.started": "2024-07-22T14:37:24.029305Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"virattt/financial-qa-10K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7859555-ba34-4929-8743-6f417ecdfe6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:29.976891Z",
     "iopub.status.busy": "2024-07-22T14:37:29.976480Z",
     "iopub.status.idle": "2024-07-22T14:37:29.984086Z",
     "shell.execute_reply": "2024-07-22T14:37:29.983004Z",
     "shell.execute_reply.started": "2024-07-22T14:37:29.976856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'ticker', 'filing'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c9be43-716d-4f89-876e-6aa6da6d3638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:29.986362Z",
     "iopub.status.busy": "2024-07-22T14:37:29.985493Z",
     "iopub.status.idle": "2024-07-22T14:37:30.003147Z",
     "shell.execute_reply": "2024-07-22T14:37:30.002052Z",
     "shell.execute_reply.started": "2024-07-22T14:37:29.986328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What area did NVIDIA initially focus on before expanding to other computationally intensive fields?',\n",
       "  'What are some of the recent applications of GPU-powered deep learning as mentioned by NVIDIA?',\n",
       "  'What significant invention did NVIDIA create in 1999?'],\n",
       " 'answer': ['NVIDIA initially focused on PC graphics.',\n",
       "  'Recent applications of GPU-powered deep learning include recommendation systems, large language models, and generative AI.',\n",
       "  'NVIDIA invented the GPU in 1999.'],\n",
       " 'context': ['Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.',\n",
       "  'Some of the most recent applications of GPU-powered deep learning include recommendation systems, which are AI algorithms trained to understand the preferences, previous decisions, and characteristics of people and products using data gathered about their interactions, large language models, which can recognize, summarize, translate, predict and generate text and other content based on knowledge gained from massive datasets, and generative AI, which uses algorithms that create new content, including audio, code, images, text, simulations, and videos, based on the data they have been trained on.',\n",
       "  'Our invention of the GPU in 1999 defined modern computer graphics and established NVIDIA as the leader in computer graphics.'],\n",
       " 'ticker': ['NVDA', 'NVDA', 'NVDA'],\n",
       " 'filing': ['2023_10K', '2023_10K', '2023_10K']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56291769-66b2-48e2-9ea3-60fbdb71cd0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.004930Z",
     "iopub.status.busy": "2024-07-22T14:37:30.004539Z",
     "iopub.status.idle": "2024-07-22T14:37:30.056179Z",
     "shell.execute_reply": "2024-07-22T14:37:30.055190Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.004897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(row):\n",
    "    return {\n",
    "        \"question\": row[\"question\"],\n",
    "        \"context\": row[\"context\"],\n",
    "        \"answer\": row[\"answer\"]\n",
    "    }\n",
    "new_dataset = dataset.map(process, num_proc=8, \n",
    "                          remove_columns=dataset[\"train\"].column_names)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d267eb99-2041-4cea-bd9d-3e55219aff12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.064416Z",
     "iopub.status.busy": "2024-07-22T14:37:30.064072Z",
     "iopub.status.idle": "2024-07-22T14:37:30.095105Z",
     "shell.execute_reply": "2024-07-22T14:37:30.094128Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.064387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \n",
       "0  Since our original focus on PC graphics, we ha...  \n",
       "1  Some of the most recent applications of GPU-po...  \n",
       "2  Our invention of the GPU in 1999 defined moder...  \n",
       "3  NVIDIA has a platform strategy, bringing toget...  \n",
       "4  With our introduction of the CUDA programming ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_dataset['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41510e61-34a3-4ec8-b7bc-4fc074ebbcfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.096567Z",
     "iopub.status.busy": "2024-07-22T14:37:30.096263Z",
     "iopub.status.idle": "2024-07-22T14:37:30.108840Z",
     "shell.execute_reply": "2024-07-22T14:37:30.107879Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.096541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  answer  context\n",
       "False     False   False      7000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ee50f-e226-4512-8b20-fc1ac3aad4d3",
   "metadata": {},
   "source": [
    "### to chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63c0a661-8620-444f-842b-cf1686c93e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.110604Z",
     "iopub.status.busy": "2024-07-22T14:37:30.109965Z",
     "iopub.status.idle": "2024-07-22T14:37:30.114653Z",
     "shell.execute_reply": "2024-07-22T14:37:30.113659Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.110577Z"
    }
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2404347b-103d-4ae6-b433-9c038a9598e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.116121Z",
     "iopub.status.busy": "2024-07-22T14:37:30.115817Z",
     "iopub.status.idle": "2024-07-22T14:37:30.122493Z",
     "shell.execute_reply": "2024-07-22T14:37:30.121488Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.116095Z"
    }
   },
   "outputs": [],
   "source": [
    "row = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23028cfe-fda9-477c-8924-cdfb49857ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.124211Z",
     "iopub.status.busy": "2024-07-22T14:37:30.123856Z",
     "iopub.status.idle": "2024-07-22T14:37:30.132172Z",
     "shell.execute_reply": "2024-07-22T14:37:30.131110Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.124181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dedent(\n",
    "    f\"\"\"\n",
    "{row[\"question\"]}\n",
    "\n",
    "Information:\n",
    "\n",
    "```\n",
    "{row[\"context\"]}\n",
    "```\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "097bb1d4-9ccc-4131-8018-b4a69d87bd95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.134257Z",
     "iopub.status.busy": "2024-07-22T14:37:30.133471Z",
     "iopub.status.idle": "2024-07-22T14:37:30.141558Z",
     "shell.execute_reply": "2024-07-22T14:37:30.140456Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.134226Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_example(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd85944b-b296-4209-a6d6-34872782e52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.143587Z",
     "iopub.status.busy": "2024-07-22T14:37:30.142958Z",
     "iopub.status.idle": "2024-07-22T14:37:30.572588Z",
     "shell.execute_reply": "2024-07-22T14:37:30.571836Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.143553Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8faea26-d4cc-4294-a70d-07a0ad52103d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.573214Z",
     "iopub.status.busy": "2024-07-22T14:37:30.573094Z",
     "iopub.status.idle": "2024-07-22T14:37:30.577770Z",
     "shell.execute_reply": "2024-07-22T14:37:30.577010Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.573204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "NVIDIA initially focused on PC graphics.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6f1da6a-ede6-416c-ac0b-b155568efd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.578376Z",
     "iopub.status.busy": "2024-07-22T14:37:30.578249Z",
     "iopub.status.idle": "2024-07-22T14:37:30.593179Z",
     "shell.execute_reply": "2024-07-22T14:37:30.592441Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.578366Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_tokens(row: Dict) -> int:\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row[\"text\"],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False,\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9edde096-b702-4b10-9ff0-c024213a16c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:30.593684Z",
     "iopub.status.busy": "2024-07-22T14:37:30.593554Z",
     "iopub.status.idle": "2024-07-22T14:37:32.047165Z",
     "shell.execute_reply": "2024-07-22T14:37:32.046385Z",
     "shell.execute_reply.started": "2024-07-22T14:37:30.593674Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e9283f7-1246-4ca4-8c20-894cf775431a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.047696Z",
     "iopub.status.busy": "2024-07-22T14:37:32.047574Z",
     "iopub.status.idle": "2024-07-22T14:37:32.054906Z",
     "shell.execute_reply": "2024-07-22T14:37:32.054190Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.047685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Since our original focus on PC graphics, we ha...   \n",
       "1  Some of the most recent applications of GPU-po...   \n",
       "2  Our invention of the GPU in 1999 defined moder...   \n",
       "3  NVIDIA has a platform strategy, bringing toget...   \n",
       "4  With our introduction of the CUDA programming ...   \n",
       "\n",
       "                                                text  token_count  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...           75  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...          171  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...           73  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...           97  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...           83  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dbe266b-9e43-4868-b874-c96c4c02ee38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.055525Z",
     "iopub.status.busy": "2024-07-22T14:37:32.055405Z",
     "iopub.status.idle": "2024-07-22T14:37:32.071104Z",
     "shell.execute_reply": "2024-07-22T14:37:32.070373Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.055515Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(df.token_count, weights=np.ones(len(df.token_count)) / len(df.token_count))\n",
    "# plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "# plt.xlabel(\"Tokens\")\n",
    "# plt.ylabel(\"Percentage\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa729957-fdce-4ab5-a01d-39e058f76be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.071595Z",
     "iopub.status.busy": "2024-07-22T14:37:32.071476Z",
     "iopub.status.idle": "2024-07-22T14:37:32.198426Z",
     "shell.execute_reply": "2024-07-22T14:37:32.197683Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.071585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df.token_count, stat='probability', bins=30)\n",
    "\n",
    "#  y \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "# \n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "\n",
    "# \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2eff5c0-7013-4bbd-a201-e1e18ce30116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.198952Z",
     "iopub.status.busy": "2024-07-22T14:37:32.198829Z",
     "iopub.status.idle": "2024-07-22T14:37:32.205888Z",
     "shell.execute_reply": "2024-07-22T14:37:32.205138Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.198942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6997, 7000, 0.9995714285714286)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.token_count < 512]), len(df), len(df[df.token_count < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a71b9721-744b-4bdf-9e7e-343d8a76c08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.206538Z",
     "iopub.status.busy": "2024-07-22T14:37:32.206404Z",
     "iopub.status.idle": "2024-07-22T14:37:32.213185Z",
     "shell.execute_reply": "2024-07-22T14:37:32.212464Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.206527Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df[df.token_count < 512]\n",
    "# df = df.sample(6000)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ada232d2-ee1d-4549-b200-bb0f5042fa30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.213653Z",
     "iopub.status.busy": "2024-07-22T14:37:32.213541Z",
     "iopub.status.idle": "2024-07-22T14:37:32.223600Z",
     "shell.execute_reply": "2024-07-22T14:37:32.222857Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.213644Z"
    }
   },
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df, test_size=0.2)\n",
    "val, test = train_test_split(temp, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7e66712-ea1c-4e8d-b09b-af13bc959514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.224131Z",
     "iopub.status.busy": "2024-07-22T14:37:32.224004Z",
     "iopub.status.idle": "2024-07-22T14:37:32.232744Z",
     "shell.execute_reply": "2024-07-22T14:37:32.232042Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.224120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 1120, 280)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3f2be7b-fece-4d47-accc-e19f70c05178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.233236Z",
     "iopub.status.busy": "2024-07-22T14:37:32.233116Z",
     "iopub.status.idle": "2024-07-22T14:37:32.240740Z",
     "shell.execute_reply": "2024-07-22T14:37:32.239997Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.233225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.16, 0.04)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) / len(df), len(val) / len(df), len(test) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "025247a8-ad71-4fc3-bc51-c6665eba267b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.241439Z",
     "iopub.status.busy": "2024-07-22T14:37:32.241294Z",
     "iopub.status.idle": "2024-07-22T14:37:32.290143Z",
     "shell.execute_reply": "2024-07-22T14:37:32.289311Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.241426Z"
    }
   },
   "outputs": [],
   "source": [
    "train.sample(n=5000).to_json(\"./data/train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=1000).to_json(\"./data/val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=250).to_json(\"./data/test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c855dc93-e0b7-4c5f-9c91-3fde2d159d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:32.290842Z",
     "iopub.status.busy": "2024-07-22T14:37:32.290708Z",
     "iopub.status.idle": "2024-07-22T14:37:33.390828Z",
     "shell.execute_reply": "2024-07-22T14:37:33.389639Z",
     "shell.execute_reply.started": "2024-07-22T14:37:32.290831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3009d970a0462583496b566b042a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d550a59da54f15bcd15a337fcaa9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3440f2fe2b6540c5b02e7b07d0e850d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef707757fdd547f0baa05caff6bc4c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc8813c884b4be1bbf614883071a7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"./data/train.json\", \n",
    "                \"validation\": \"./data/val.json\", \n",
    "                \"test\": \"./data/test.json\"},\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c57ea-10ff-4d5a-8057-19d04c4a6ddd",
   "metadata": {},
   "source": [
    "## sft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58b4d1-daa9-47cf-8925-a5f03b62833e",
   "metadata": {},
   "source": [
    "### test on llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b03a729-a0bd-481e-b61a-9e3179d2f5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:33.392733Z",
     "iopub.status.busy": "2024-07-22T14:37:33.392325Z",
     "iopub.status.idle": "2024-07-22T14:37:33.398770Z",
     "shell.execute_reply": "2024-07-22T14:37:33.397867Z",
     "shell.execute_reply.started": "2024-07-22T14:37:33.392699Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df72d931-7e78-4b7f-8d26-874d3c3c64fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:33.400664Z",
     "iopub.status.busy": "2024-07-22T14:37:33.399684Z",
     "iopub.status.idle": "2024-07-22T14:37:33.409138Z",
     "shell.execute_reply": "2024-07-22T14:37:33.407923Z",
     "shell.execute_reply.started": "2024-07-22T14:37:33.400624Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {data_row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {data_row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cd12b41-dcdc-47bf-97cd-9d5db7add682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:33.411353Z",
     "iopub.status.busy": "2024-07-22T14:37:33.410660Z",
     "iopub.status.idle": "2024-07-22T14:37:33.420249Z",
     "shell.execute_reply": "2024-07-22T14:37:33.419041Z",
     "shell.execute_reply.started": "2024-07-22T14:37:33.411315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does Amazon fulfill customer orders?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Amazon fulfills customer orders using its North America and International fulfillment networks, co-sourced and outsourced arrangements in certain countries, digital delivery, and physical stores.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5143a708-5db4-48f5-b946-8120bb7a965b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:33.422494Z",
     "iopub.status.busy": "2024-07-22T14:37:33.421800Z",
     "iopub.status.idle": "2024-07-22T14:37:35.878207Z",
     "shell.execute_reply": "2024-07-22T14:37:35.877276Z",
     "shell.execute_reply.started": "2024-07-22T14:37:33.422456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     Amazon fulfills customer orders through a combination of North America and International fulfillment networks operated by the company, co-sourced and outsourced arrangements in some countries, digital delivery, and through its physical stores.\n",
      "prediction: According to the information, Amazon fulfills customer orders using:\n",
      "\n",
      "1. North America and International fulfillment networks\n",
      "2. Co-sourced and outsourced arrangements in certain countries\n",
      "3. Digital delivery\n",
      "4. Physical stores\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f8cb284-fe81-4a51-b99e-ebb86d7c7c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:35.878987Z",
     "iopub.status.busy": "2024-07-22T14:37:35.878849Z",
     "iopub.status.idle": "2024-07-22T14:37:35.883730Z",
     "shell.execute_reply": "2024-07-22T14:37:35.883003Z",
     "shell.execute_reply.started": "2024-07-22T14:37:35.878976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who holds the patents for the active pharmaceutical ingredients of some of the company's products?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Patents covering certain of the active pharmaceutical ingredients (\"API\") of some of our products are held by third parties. We acquired exclusive rights to these patents in the agreements we have with these parties.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][1]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b95a2962-398c-4534-be2a-94092e49cb68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:35.884370Z",
     "iopub.status.busy": "2024-07-22T14:37:35.884248Z",
     "iopub.status.idle": "2024-07-22T14:37:36.737416Z",
     "shell.execute_reply": "2024-07-22T14:37:36.736632Z",
     "shell.execute_reply.started": "2024-07-22T14:37:35.884359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     The patents for the active pharmaceutical ingredients of some of the company's products are held by third parties, from whom the company has acquired exclusive rights through agreements.\n",
      "prediction: Third parties hold the patents for the active pharmaceutical ingredients of some of the company's products.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f455bef-c521-4dea-bf2b-fae4745772bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.738098Z",
     "iopub.status.busy": "2024-07-22T14:37:36.737970Z",
     "iopub.status.idle": "2024-07-22T14:37:36.742010Z",
     "shell.execute_reply": "2024-07-22T14:37:36.741248Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.738087Z"
    }
   },
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for row in tqdm(dataset[\"test\"]):\n",
    "#     prompt = create_test_prompt(row)\n",
    "#     outputs = pipe(prompt)\n",
    "#     rows.append(\n",
    "#         {\n",
    "#             \"question\": row[\"question\"],\n",
    "#             \"context\": row[\"context\"],\n",
    "#             \"prompt\": prompt,\n",
    "#             \"answer\": row[\"answer\"],\n",
    "#             \"untrained_prediction\": outputs[0][\"generated_text\"],\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# predictions_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a448e4f-b9ef-4d6a-90b7-d74f9a3f7428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.742525Z",
     "iopub.status.busy": "2024-07-22T14:37:36.742402Z",
     "iopub.status.idle": "2024-07-22T14:37:36.760062Z",
     "shell.execute_reply": "2024-07-22T14:37:36.758850Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.742514Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.arange(len(dataset[\"test\"])) // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b22c2e8-aaa3-4c00-94c6-98e8711a9a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.760801Z",
     "iopub.status.busy": "2024-07-22T14:37:36.760620Z",
     "iopub.status.idle": "2024-07-22T14:37:36.768227Z",
     "shell.execute_reply": "2024-07-22T14:37:36.767424Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.760785Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 64  # Adjust the batch size according to your GPU memory\n",
    "# for batch in tqdm(dataset[\"test\"].to_pandas().groupby(np.arange(len(dataset[\"test\"])) // batch_size)):\n",
    "#     batch_df = batch[1]\n",
    "#     prompts = batch_df.apply(create_test_prompt, axis=1).tolist()\n",
    "#     outputs = pipe(prompts)\n",
    "\n",
    "#     for i, output in enumerate(outputs):\n",
    "#         # print(output)\n",
    "#         rows.append(\n",
    "#             {\n",
    "#                 \"question\": batch_df.iloc[i][\"question\"],\n",
    "#                 \"context\": batch_df.iloc[i][\"context\"],\n",
    "#                 \"prompt\": prompts[i],\n",
    "#                 \"answer\": batch_df.iloc[i][\"answer\"],\n",
    "#                 \"untrained_prediction\": output[0][\"generated_text\"],\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "# predictions_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef6216-ee05-469e-94a2-60dacae5e7dc",
   "metadata": {},
   "source": [
    "### Train on Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cf458-6cea-4c97-8302-c5ffa67c162b",
   "metadata": {},
   "source": [
    "- collate_fn\n",
    "    - DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "371f3df3-11a2-4b35-88f3-c441c6df9265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.768910Z",
     "iopub.status.busy": "2024-07-22T14:37:36.768741Z",
     "iopub.status.idle": "2024-07-22T14:37:36.782708Z",
     "shell.execute_reply": "2024-07-22T14:37:36.781621Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.768895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is the Chief Financial Officer and since when?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Richard A. Galanti | Executive Vice President and Chief Financial Officer. Mr. Galanti has been a director since January 1995.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Richard A. Galanti is the Executive Vice President and Chief Financial Officer, and he has been in this role since 1993.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "examples = [dataset[\"train\"][0][\"text\"]]\n",
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93337f0a-a567-43c7-bd0e-c571ea316e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.783378Z",
     "iopub.status.busy": "2024-07-22T14:37:36.783204Z",
     "iopub.status.idle": "2024-07-22T14:37:36.790885Z",
     "shell.execute_reply": "2024-07-22T14:37:36.790030Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.783363Z"
    }
   },
   "outputs": [],
   "source": [
    "response_template = \"<|end_header_id|>\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "# collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc76b73f-ada4-496c-9c55-3735727cc90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.791653Z",
     "iopub.status.busy": "2024-07-22T14:37:36.791459Z",
     "iopub.status.idle": "2024-07-22T14:37:36.799834Z",
     "shell.execute_reply": "2024-07-22T14:37:36.798982Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.791637Z"
    }
   },
   "outputs": [],
   "source": [
    "encodings = [tokenizer(e) for e in examples]\n",
    "dataloader = DataLoader(encodings, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6789d4c2-9124-4fac-9242-8f05382e0f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.800911Z",
     "iopub.status.busy": "2024-07-22T14:37:36.800700Z",
     "iopub.status.idle": "2024-07-22T14:37:36.809781Z",
     "shell.execute_reply": "2024-07-22T14:37:36.808923Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.800894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a79ec3ab-8b2c-4614-844c-addb6abd90b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.810976Z",
     "iopub.status.busy": "2024-07-22T14:37:36.810743Z",
     "iopub.status.idle": "2024-07-22T14:37:36.817792Z",
     "shell.execute_reply": "2024-07-22T14:37:36.816922Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.810956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,  10464,   1193,    279,   2038,\n",
       "            311,   4320,    279,   3488, 128009, 128006,    882, 128007,    271,\n",
       "          15546,    374,    279,  14681,  17961,  20148,    323,   2533,    994,\n",
       "           1980,  15218,   1473,  14196,   4077,  42315,    362,     13,  10845,\n",
       "          15719,    765,  18362,  23270,   4900,    323,  14681,  17961,  20148,\n",
       "             13,   4491,     13,  10845,  15719,    706,   1027,    264,   7690,\n",
       "           2533,   6186,    220,   2550,     20,    627,  74694, 128009, 128006,\n",
       "          78191, 128007,    271,  42315,    362,     13,  10845,  15719,    374,\n",
       "            279,  18362,  23270,   4900,    323,  14681,  17961,  20148,     11,\n",
       "            323,    568,    706,   1027,    304,    420,   3560,   2533,    220,\n",
       "           2550,     18,     13, 128009]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1f876bc-6a6c-41cb-ac40-720c3b51bc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.818986Z",
     "iopub.status.busy": "2024-07-22T14:37:36.818741Z",
     "iopub.status.idle": "2024-07-22T14:37:36.826073Z",
     "shell.execute_reply": "2024-07-22T14:37:36.825195Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.818965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,    271,  42315,    362,     13,  10845,  15719,    374,\n",
       "            279,  18362,  23270,   4900,    323,  14681,  17961,  20148,     11,\n",
       "            323,    568,    706,   1027,    304,    420,   3560,   2533,    220,\n",
       "           2550,     18,     13, 128009]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0c72e76-3a42-4295-a471-7357af8c3edc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.827268Z",
     "iopub.status.busy": "2024-07-22T14:37:36.827026Z",
     "iopub.status.idle": "2024-07-22T14:37:36.833351Z",
     "shell.execute_reply": "2024-07-22T14:37:36.832511Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.827248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n126 countries and territories<|eot_id|>'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([271,   9390,   5961,    323,  39543, 128009])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963fa2a-db32-445b-a230-d99fc3585ea9",
   "metadata": {},
   "source": [
    "### lora setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aa06fb1-eabb-48f5-b8b7-e365ec25f510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.834552Z",
     "iopub.status.busy": "2024-07-22T14:37:36.834309Z",
     "iopub.status.idle": "2024-07-22T14:37:36.844921Z",
     "shell.execute_reply": "2024-07-22T14:37:36.843754Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.834531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128264, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "486f1889-d34d-41b3-ade6-11eac09c6c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:36.845856Z",
     "iopub.status.busy": "2024-07-22T14:37:36.845608Z",
     "iopub.status.idle": "2024-07-22T14:37:37.994834Z",
     "shell.execute_reply": "2024-07-22T14:37:37.994320Z",
     "shell.execute_reply.started": "2024-07-22T14:37:36.845835Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca025777-4626-4459-921c-a95dfe011d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:37.995626Z",
     "iopub.status.busy": "2024-07-22T14:37:37.995470Z",
     "iopub.status.idle": "2024-07-22T14:37:38.002844Z",
     "shell.execute_reply": "2024-07-22T14:37:38.002397Z",
     "shell.execute_reply.started": "2024-07-22T14:37:37.995614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83,886,080 || all params: 8,114,212,864 || trainable%: 1.0338166055782685\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3875d-8d85-4251-82bb-36fa55a20f3f",
   "metadata": {},
   "source": [
    "### sft train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a99ce81-ed11-4f7a-9dc3-70b4dbded16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:38.003531Z",
     "iopub.status.busy": "2024-07-22T14:37:38.003391Z",
     "iopub.status.idle": "2024-07-22T14:37:39.535086Z",
     "shell.execute_reply": "2024-07-22T14:37:39.534099Z",
     "shell.execute_reply.started": "2024-07-22T14:37:38.003520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"experiments\"\n",
    "\n",
    "# ssh -L 6006:localhost:6006 user@remote_server\n",
    "# localhost:6006\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"experiments/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "597f6dd4-3515-4651-884a-7a7bb5933f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:39.536439Z",
     "iopub.status.busy": "2024-07-22T14:37:39.536178Z",
     "iopub.status.idle": "2024-07-22T14:37:39.541036Z",
     "shell.execute_reply": "2024-07-22T14:37:39.540112Z",
     "shell.execute_reply.started": "2024-07-22T14:37:39.536418Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b25050a-42fa-4b91-baf5-539aa3c6bf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:39.542249Z",
     "iopub.status.busy": "2024-07-22T14:37:39.542020Z",
     "iopub.status.idle": "2024-07-22T14:37:39.560024Z",
     "shell.execute_reply": "2024-07-22T14:37:39.559140Z",
     "shell.execute_reply.started": "2024-07-22T14:37:39.542230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4aae8be-d911-4558-8987-4fb6a162731f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:39.561203Z",
     "iopub.status.busy": "2024-07-22T14:37:39.560979Z",
     "iopub.status.idle": "2024-07-22T14:37:39.569104Z",
     "shell.execute_reply": "2024-07-22T14:37:39.567848Z",
     "shell.execute_reply.started": "2024-07-22T14:37:39.561185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global_step=156\n",
    "5000/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fbabb35-c10f-4c24-af80-e5b8222e0f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:39.571897Z",
     "iopub.status.busy": "2024-07-22T14:37:39.570881Z",
     "iopub.status.idle": "2024-07-22T14:37:41.136642Z",
     "shell.execute_reply": "2024-07-22T14:37:41.135861Z",
     "shell.execute_reply.started": "2024-07-22T14:37:39.571856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c640923cc14c4f4b9c9207b4607f2385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4acd8ffba2425b977afafe431c5896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    save_steps=0.2,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,  # or bf16=True,\n",
    "    save_strategy=\"steps\",\n",
    "    warmup_ratio=0.1,\n",
    "    save_total_limit=2,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,  # We template with special tokens\n",
    "        \"append_concat_token\": False,  # No need to add additional separator token\n",
    "    },\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42844415-b683-42e6-9c42-20032d500067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:37:41.137493Z",
     "iopub.status.busy": "2024-07-22T14:37:41.137219Z",
     "iopub.status.idle": "2024-07-22T14:53:14.170906Z",
     "shell.execute_reply": "2024-07-22T14:53:14.170136Z",
     "shell.execute_reply.started": "2024-07-22T14:37:41.137480Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 15:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.512541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.499013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.492370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.485425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e6f80-4b8787ca16e7beb664bf2bfe;bc328607-63d4-465d-b8e6-c722f4e24cb2)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e7047-5b57cb050b67522108911b66;cbf64976-6f1e-468c-b593-ad3213bc293c)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e7110-452019dd739882c934f85de2;a71221d9-cb14-4d77-a74c-c5f462b5858a)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e71db-4e3a834f6afce7466e212a8e;e5b6c150-8faa-4db8-b1ef-bba0c9fad838)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e7259-4a1563f440d3505868f9a88a;227a1bf2-7901-4d51-b7a9-d9d6946188a6)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156, training_loss=0.4872007415844844, metrics={'train_runtime': 932.845, 'train_samples_per_second': 5.36, 'train_steps_per_second': 0.167, 'total_flos': 4.268560560979968e+16, 'train_loss': 0.4872007415844844, 'epoch': 0.9984})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cbbdd5f-8755-4eb1-a022-8efa0be77c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T14:54:54.499905Z",
     "iopub.status.busy": "2024-07-22T14:54:54.499606Z",
     "iopub.status.idle": "2024-07-22T14:54:57.869967Z",
     "shell.execute_reply": "2024-07-22T14:54:57.868487Z",
     "shell.execute_reply.started": "2024-07-22T14:54:54.499881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-669e72be-751ff670378fa92036c20be7;a37c2fb4-0710-46e4-a854-b8bd8b8baae8)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1c53f-4ec3-4cb9-aa31-c8c2f28b3396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
